{
  "content": "The chunk introduces the challenges of managing texture memory across different graphics cards, emphasizing how loading too many textures can deplete available memory and cause issues like rendering artifacts or crashes. It sets the stage for discussing solutions provided by Panda to mitigate these problems.\n\nTexture Management\n\nDifferent graphics cards provide different amounts of texture memory. If you're loading a lot of different textures, especially if they're large, you can easily consume all of your available texture memory. In principle, this shouldn't cause problems, as long as you don't have all of your textures onscreen at once: both OpenGL and DirectX are supposed to automatically evict textures from graphics memory as needed.\n\nIn practice, it doesn't always work this cleanly. In some integrated graphics cards, the \"graphics memory\" is actually your system memory, so the graphics driver never needs to evict textures--but if you load too many textures, there may not be enough memory left for your application. Furthermore, some graphics drivers have major bugs that manifest as you start to approach the limit of your graphics memory, causing strange rendering artifacts or even crashes.",
  "metadata": {
    "doc_type": "rst",
    "doc_id": "doc_680",
    "parent": "processed_documents/context_documents/ce84f0cc_97c5dd71_texture-management.json",
    "chunk_number": 7626
  }
}