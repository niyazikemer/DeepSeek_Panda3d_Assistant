{
  "content": "Shaders and Coordinate Spaces\n\nThe Major Coordinate Spaces\n\nWhen writing complex shaders, it is often necessary to do a lot of coordinate system conversion. In order to get this right, it is important to be aware of all the different coordinate spaces that panda uses. You must know what \"space\" the coordinate is in. Here is a list of the major coordinate spaces:\n\nIn OpenGL, \"clip space\" and \"API clip space\" are equivalent.\n\nSupplying Translation Matrices to a Shader\n\nYou can use a shader parameter named \"trans_x_to_y\" to automatically obtain a matrix that converts any coordinate system to any other. The words x and y can be \"model,\" \"world,\" \"view,\" \"apiview,\" \"clip,\" or \"apiclip.\" Using this notation, you can build up almost any transform matrix that you might need. Here is a short list of popular matrices that can be recreated using this syntax. Of course, this isn't even close to exhaustive: there are seven keywords, so there are 7x7 possible matrices, of which 7 are the identity matrix.\n\nDesired Matrix Source Syntax GLSL input The Modelview Matrix gsg.getInternalTransform() trans_model_to_apiview p3d_ModelViewMatrix The Projection Matrix gsg.getProjectionMat() trans_apiview_to_apiclip p3d_ProjectionMatrix the DirectX world matrix model.getNetTransform() trans_model_to_world p3d_ModelMatrix the DirectX view matrix scene.getCsWorldTransform() trans_world_to_apiview p3d_ViewMatrix scene.getCameraTransform() trans_view_to_world scene.getWorldTransform() trans_world_to_view gsg.getExternalTransform() trans_model_to_view gsg.getCsTransform() trans_view_to_apiview gsg.getInvCsTransform() trans_apiview_to_view\n\nA note about GLSL inputs\n\nThe p3d_ModelViewMatrix and p3d_ProjectionMatrix by default transform to and from \"apiview\" space, in order to match the behavior of the equivalent gl_-prefixed inputs from earlier GLSL versions. Panda3D traditionally uses a right-handed Y-up coordinate space for all OpenGL operations because some OpenGL fixed-function features rely on this space in order to produce the correct results.\n\nHowever, if you develop a largely shader-based application and/or don't really use features like fixed-function sphere mapping, you may choose to disable this conversion to Y-up space. This will define \"apiview\" space to be equivalent to \"view\" space, which simplifies many things, and will reduce overhead due to unnecessary coordinate space conversion, especially as \"apiclip\" and \"clip\" are already equivalent in OpenGL as well.\n\nTo do this, place gl-coordinate-system default in your Config.prc file.\n\nRecommendation: Don't use API View Space or API Clip Space\n\nThe coordinate systems \"API View Space\" and \"API Clip Space\" are not very useful. The fact that their behavior changes from one rendering API to the next makes them extremely hard to work with. Of course, you have to use the composed modelview/projection matrix to transform your vertices, and in doing so, you are implicitly using these spaces. But aside from that, it is strongly recommended that you not use these spaces for anything else.\n\nModel_of_x, View_of_x, Clip_of_x\n\nWhen you use the word \"model\" in a trans directive, you implicitly mean \"the model currently being rendered.\" But you can make any nodepath accessible to the shader subsystem using .NodePath.set_shader_input():\n\npython\n\nmyhouse = loader.loadModel(\"myhouse\")\nrender.setShaderInput(\"myhouse\", myhouse)\n\ncpp\n\nNodePath myhouse = window->load_model(framework.get_models(), \"myhouse\");\nwindow->get_render().set_shader_input(\"myhouse\", myhouse);\n\nThen, in the shader, you can convert coordinates to or from the model-space of this particular nodepath:\n\nuniform float4x4 trans_world_to_model_of_myhouse\n\nor, use the syntactic shorthand:\n\nuniform float4x4 trans_world_to_myhouse\n\nLikewise, you can create a camera and pass it into the shader subsystem. This is particularly useful when doing shadow mapping:\n\npython\n\nrender.setShaderInput(\"shadowcam\", shadowcam)\n\ncpp\n\nrender.set_shader_input(\"shadowcam\", shadowcam);\n\nNow you can transform vertices into the clip-space of the given camera using this notation:\n\nuniform float4x4 trans_model_to_clip_of_shadowcam\n\nIf you transform your model's vertices from model space into the clip space of a shadow camera, the resulting (X/W,Y/W) values can be used as texture coordinates to projectively texture the shadow map onto the scene (after rescaling them), and the (Z/W) value can be compared to the value stored in the depth map (again, after rescaling it).\n\nPanda does support the notation \"trans_x_to_apiclip_of_y\", but again, our recommendation is not to use it.\n\nYou can transform a vertex to the view space of an alternate camera, using \"view of x.\" In fact, this is exactly identical to \"model of x,\" but it's probably good form to use \"view of x\" when x is a camera.",
  "metadata": {
    "source": "corpus_panda3d/collected_docs/7f49f363_coordinate-spaces.rst",
    "doc_type": "rst",
    "file_path": "processed_documents/context_documents/84f019c6_7f49f363_coordinate-spaces.json",
    "doc_id": "doc_557"
  }
}